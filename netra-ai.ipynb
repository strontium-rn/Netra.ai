{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1512919,"sourceType":"datasetVersion","datasetId":611716}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os                                                             #for interacting with os for files \nimport cv2                                                            #part of openCV for image processing tasks\nimport pandas as pd                                                   #handling and managing datas\nimport numpy as np                                                    #for numerical operations\nimport matplotlib.pyplot as plt                                       #used to create visualizations\nimport seaborn as sns                                                 #advance visulazation tools\nfrom sklearn.metrics import confusion_matrix, classification_report   #for evaluating ml models by generating metrics\nfrom sklearn.model_selection import train_test_split                  #splits the data for model evaluation and validation\nimport tensorflow as tf                                               #deeplearning framework for creating and training neural networks\nfrom tensorflow.keras.models import Sequential                        #used to define a feed forward model by stacking layers sequentially\nfrom tensorflow.keras.layers import Dropout                           #manipulates neurons in neural network\nfrom tensorflow.keras.metrics import Recall, Precision                #metrics to evaluate model performance\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator   #for agumentation\nfrom tensorflow.keras.optimizers import Adam                          #adjusts the learning rate during training\nfrom tensorflow.keras.applications import InceptionV3                 #pretrained deeplearing models for transfer learning\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.layers import Input,concatenate,Dense, GlobalAveragePooling2D, Flatten                #for input layer and merging multiple layers\nfrom tensorflow.keras.models import Model, clone_model                #enables builiding complex model, allowing more flexible network\nfrom tensorflow.keras.callbacks import EarlyStopping                  #monitors model performance and stops the training of model to prevent overfitting and saves time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:38.171346Z","iopub.execute_input":"2025-02-02T09:31:38.171621Z","iopub.status.idle":"2025-02-02T09:31:46.476949Z","shell.execute_reply.started":"2025-02-02T09:31:38.171591Z","shell.execute_reply":"2025-02-02T09:31:46.476029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ocular-disease-recognition-odir5k/full_df.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.477784Z","iopub.execute_input":"2025-02-02T09:31:46.478239Z","iopub.status.idle":"2025-02-02T09:31:46.561689Z","shell.execute_reply.started":"2025-02-02T09:31:46.478216Z","shell.execute_reply":"2025-02-02T09:31:46.560947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.562481Z","iopub.execute_input":"2025-02-02T09:31:46.562680Z","iopub.status.idle":"2025-02-02T09:31:46.585844Z","shell.execute_reply.started":"2025-02-02T09:31:46.562661Z","shell.execute_reply":"2025-02-02T09:31:46.585019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.587409Z","iopub.execute_input":"2025-02-02T09:31:46.587634Z","iopub.status.idle":"2025-02-02T09:31:46.613940Z","shell.execute_reply.started":"2025-02-02T09:31:46.587614Z","shell.execute_reply":"2025-02-02T09:31:46.613164Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Normal (N),\nDiabetes (D),\nGlaucoma (G),\nCataract (C),\nAge related Macular Degeneration (A),\nHypertension (H),\nPathological Myopia (M),\nOther diseases/abnormalities (O)","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.615478Z","iopub.execute_input":"2025-02-02T09:31:46.615757Z","iopub.status.idle":"2025-02-02T09:31:46.646687Z","shell.execute_reply.started":"2025-02-02T09:31:46.615731Z","shell.execute_reply":"2025-02-02T09:31:46.645918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.647514Z","iopub.execute_input":"2025-02-02T09:31:46.647783Z","iopub.status.idle":"2025-02-02T09:31:46.655580Z","shell.execute_reply.started":"2025-02-02T09:31:46.647756Z","shell.execute_reply":"2025-02-02T09:31:46.652318Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.656091Z","iopub.execute_input":"2025-02-02T09:31:46.656345Z","iopub.status.idle":"2025-02-02T09:31:46.698959Z","shell.execute_reply.started":"2025-02-02T09:31:46.656320Z","shell.execute_reply":"2025-02-02T09:31:46.698208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.barplot(data=df, x=\"labels\", y=\"Patient Age\", hue=\"Patient Sex\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:46.699740Z","iopub.execute_input":"2025-02-02T09:31:46.700004Z","iopub.status.idle":"2025-02-02T09:31:47.444626Z","shell.execute_reply.started":"2025-02-02T09:31:46.699983Z","shell.execute_reply":"2025-02-02T09:31:47.443674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if 'ID' in df.columns:\n    df = df.drop('ID', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:47.445461Z","iopub.execute_input":"2025-02-02T09:31:47.445780Z","iopub.status.idle":"2025-02-02T09:31:47.452424Z","shell.execute_reply.started":"2025-02-02T09:31:47.445745Z","shell.execute_reply":"2025-02-02T09:31:47.451573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:47.453462Z","iopub.execute_input":"2025-02-02T09:31:47.453674Z","iopub.status.idle":"2025-02-02T09:31:47.468821Z","shell.execute_reply.started":"2025-02-02T09:31:47.453655Z","shell.execute_reply":"2025-02-02T09:31:47.468015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Patient Sex'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:47.469648Z","iopub.execute_input":"2025-02-02T09:31:47.469941Z","iopub.status.idle":"2025-02-02T09:31:47.485467Z","shell.execute_reply.started":"2025-02-02T09:31:47.469913Z","shell.execute_reply":"2025-02-02T09:31:47.484575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\n\n# Suppress specific warning\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\", category=FutureWarning)\n    plt.figure(figsize=(6, 6))\n    sns.histplot(data=df, x=\"Patient Age\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:47.486594Z","iopub.execute_input":"2025-02-02T09:31:47.486946Z","iopub.status.idle":"2025-02-02T09:31:47.798761Z","shell.execute_reply.started":"2025-02-02T09:31:47.486911Z","shell.execute_reply":"2025-02-02T09:31:47.797917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6,6))\nplt.pie(df['labels'].value_counts(), autopct=\"%0.1F%%\",\n       labels=['Normal','Diabetes','Glaucoma','Cataract','Age related Macular Degeneration','Hypertension',\n                'Pathological Myopia','Other diseases/abnormalities'],\n       shadow=True, explode=[0.2, 0.09, 0,0,0,0,0,0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:47.801387Z","iopub.execute_input":"2025-02-02T09:31:47.801616Z","iopub.status.idle":"2025-02-02T09:31:48.067201Z","shell.execute_reply.started":"2025-02-02T09:31:47.801596Z","shell.execute_reply":"2025-02-02T09:31:48.066155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sex_counts = df['Patient Sex'].value_counts().reset_index()\n\nsex_counts.columns = ['Sex', 'Count']\n\nplt.figure(figsize=(6,6))\nsns.barplot(x='Sex', y='Count', data=sex_counts, color='r', width=0.5)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.069282Z","iopub.execute_input":"2025-02-02T09:31:48.069696Z","iopub.status.idle":"2025-02-02T09:31:48.271862Z","shell.execute_reply.started":"2025-02-02T09:31:48.069656Z","shell.execute_reply":"2025-02-02T09:31:48.271155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(6,6))\nplt.pie(df['Patient Sex'].value_counts(), autopct=\"%0.1F%%\",\n       labels=['Male', 'Female'], shadow=True, explode=[0.2,0])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.272662Z","iopub.execute_input":"2025-02-02T09:31:48.272891Z","iopub.status.idle":"2025-02-02T09:31:48.368630Z","shell.execute_reply.started":"2025-02-02T09:31:48.272871Z","shell.execute_reply":"2025-02-02T09:31:48.368042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_values = [\"['N']\", \"['D']\", \"['O']\", \"['M']\", \"['H']\", \"['C']\", \"['A']\",\n       \"['G']\"]\ndf['labels'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.369077Z","iopub.execute_input":"2025-02-02T09:31:48.369377Z","iopub.status.idle":"2025-02-02T09:31:48.375767Z","shell.execute_reply.started":"2025-02-02T09:31:48.369346Z","shell.execute_reply":"2025-02-02T09:31:48.374762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder   #coverts non numerical value to numerical\nencoder = LabelEncoder()\ndf['labels'] = encoder.fit_transform(df['labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.376708Z","iopub.execute_input":"2025-02-02T09:31:48.376992Z","iopub.status.idle":"2025-02-02T09:31:48.389711Z","shell.execute_reply.started":"2025-02-02T09:31:48.376964Z","shell.execute_reply":"2025-02-02T09:31:48.388868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['labels'] = df['labels'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.390618Z","iopub.execute_input":"2025-02-02T09:31:48.390904Z","iopub.status.idle":"2025-02-02T09:31:48.404919Z","shell.execute_reply.started":"2025-02-02T09:31:48.390874Z","shell.execute_reply":"2025-02-02T09:31:48.404075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"left_images = df[['Left-Fundus','labels']]\nRight_images = df[['Right-Fundus', 'labels']]\n\nleft_images.columns = ['image', 'target']\nRight_images.columns = ['image', 'target']\n\nleft_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.405563Z","iopub.execute_input":"2025-02-02T09:31:48.405840Z","iopub.status.idle":"2025-02-02T09:31:48.426255Z","shell.execute_reply.started":"2025-02-02T09:31:48.405809Z","shell.execute_reply":"2025-02-02T09:31:48.425373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"combined_df = pd.concat([left_images, Right_images])\ncombined_df = combined_df.dropna(subset='image')\ncombined_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.427119Z","iopub.execute_input":"2025-02-02T09:31:48.427460Z","iopub.status.idle":"2025-02-02T09:31:48.450053Z","shell.execute_reply.started":"2025-02-02T09:31:48.427428Z","shell.execute_reply":"2025-02-02T09:31:48.449232Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df,test_df = train_test_split(combined_df, test_size=0.2, random_state=42)\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.450994Z","iopub.execute_input":"2025-02-02T09:31:48.451387Z","iopub.status.idle":"2025-02-02T09:31:48.470170Z","shell.execute_reply.started":"2025-02-02T09:31:48.451343Z","shell.execute_reply":"2025-02-02T09:31:48.469366Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.471044Z","iopub.execute_input":"2025-02-02T09:31:48.471400Z","iopub.status.idle":"2025-02-02T09:31:48.482633Z","shell.execute_reply.started":"2025-02-02T09:31:48.471369Z","shell.execute_reply":"2025-02-02T09:31:48.481792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images',\n    x_col = 'image',\n    y_col = 'target',\n    subest = 'training',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = 16\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:31:48.483512Z","iopub.execute_input":"2025-02-02T09:31:48.483777Z","iopub.status.idle":"2025-02-02T09:32:09.229892Z","shell.execute_reply.started":"2025-02-02T09:31:48.483740Z","shell.execute_reply":"2025-02-02T09:32:09.228959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_generator = datagen.flow_from_dataframe(\n    dataframe = test_df,\n    directory = '/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images',\n    x_col = 'image',\n    y_col = 'target',\n    class_mode = 'categorical',\n    target_size = (224,224),\n    batch_size = 32\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:32:09.230764Z","iopub.execute_input":"2025-02-02T09:32:09.231053Z","iopub.status.idle":"2025-02-02T09:32:11.345780Z","shell.execute_reply.started":"2025-02-02T09:32:09.231017Z","shell.execute_reply":"2025-02-02T09:32:11.344837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"!pip install -U efficientnet          \n\n**installed efficientnet locally because the kernel was not able to import efficientnet from tensorflow.keras.applications**","metadata":{}},{"cell_type":"code","source":"input_layer = Input(shape=(224,224,3))        #edit this cell\n\ninceptionv3 = InceptionV3(weights='imagenet', include_top=False)(input_layer)\ngop = GlobalAveragePooling2D()(inceptionv3)\n                                                                       \n\ndense1 = Dense(512, activation='relu')(gop)    #why 4 dense layers and why relu activation\ndense2 = Dense(256, activation='relu')(dense1)\ndense3 = Dense(128, activation='relu')(dense2)    #decrease dense layer and add (mukul dai)\ndense4 = Dense(64, activation='relu')(dense3)\n\noutput_layer = Dense(8, activation='sigmoid')(dense4)  #visualize this and why softmax here?\n\nmodel = Model(inputs = input_layer, outputs = output_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:32:11.346744Z","iopub.execute_input":"2025-02-02T09:32:11.347079Z","iopub.status.idle":"2025-02-02T09:32:14.306496Z","shell.execute_reply.started":"2025-02-02T09:32:11.347046Z","shell.execute_reply":"2025-02-02T09:32:14.305819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer= Adam(learning_rate=0.0001),                 #understand everthing from this\n             loss='binary_crossentropy',\n             metrics=[\n                 Recall(name=\"recall\"),\n                 Precision(name=\"Precision\"),\n                 \"accuracy\"\n             ])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:32:14.307212Z","iopub.execute_input":"2025-02-02T09:32:14.307423Z","iopub.status.idle":"2025-02-02T09:32:14.345795Z","shell.execute_reply.started":"2025-02-02T09:32:14.307405Z","shell.execute_reply":"2025-02-02T09:32:14.345182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:32:14.346436Z","iopub.execute_input":"2025-02-02T09:32:14.346628Z","iopub.status.idle":"2025-02-02T09:32:14.350059Z","shell.execute_reply.started":"2025-02-02T09:32:14.346610Z","shell.execute_reply":"2025-02-02T09:32:14.349277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint_filepath = '/kaggle/working/checkpoint.weights.h5'    \n# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n#     filepath = checkpoint_filepath,\n#     save_weights_only = True,\n#     monitor = 'val_loss',\n#     mode='min',\n#     save_best_only=True)\n# )\n# history = model.fit(train_generator, epochs=10, validation_data=validation_data-generator, callbacks=[model_checkpoint_callback])\n# history = model.fit(train_generator, epochs=20, validation_data=validation_generator, callback = [early_stopping])\n\nhistory = model.fit(train_generator, epochs=20, validation_data=validation_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-02T09:32:14.350691Z","iopub.execute_input":"2025-02-02T09:32:14.350917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}